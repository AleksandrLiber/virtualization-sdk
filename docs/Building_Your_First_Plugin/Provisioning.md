---
title: Virtualization SDK
---

# Provisioning

## What is Provisioning?
Once Delphix has a [snapshot](/References/Glossary/#snapshot) of a dataset (for example of a dSource), it is possible to quickly clone that snapshot to create a new [virtual dataset](/References/Glossary/#virtual-dataset). This new virtual dataset will be made available for use on a [target environment](/References/Glossary/#target-environment). This process is called [provisioning](/References/Glossary/#provisioning).

## Our Provisioning Strategy
For many plugins, there is a lot of work that needs to be done before a newly-provisioned virtual dataset can be made useful. For example, it might need to be registered with a running DBMS. Or, maybe some data inside the dataset needs to be changed so it behaves properly on the target environment.

In our case, however, there is very little to do. All we really require is that the files in the virtual dataset are accessible at some path on the target environment. Since the Delphix Engine takes care of mounting the data, we only need to worry about controlling *where* that data is mounted.

## Defining our Provision-Related Data Formats

We have already seen three custom data formats: for repositories, source configs, and linked sources. There are two more customizable formats:

 - [virtual sources](/References/Glossary/#virtual-source)
 - [snapshots](/References/Glossary/#snapshot)

### Snapshots
First, let us consider snapshots. Plugins can store whatever information they want alongside each snapshot. This information can be used later on when the user provisions a new virtual dataset from this snapshot. In our case, though, we have no need for any snapshot-specific information. So, our schema will be as simple as possible:

```json
{
    "type": "object"
}
```

!!! note
Because we plan not to store snapshot-specific data, we have not defined any properties for our snapshot. Snapshot-related data is only generated by the plugin, we do not have to worry about the other user-focussed schema properties we have seen before, such as `additionalProperties` and `description`.

### Virtual Source

For our [virtual source](/References/Glossary/#virtual-source), the only piece of data we really need is "Where should this dataset live on the target environment?". So, we can use a schema like this:

```json
{
    "type": "object",
    "required": "mountPath",
    "additionalProperties": false,
    "properties": {
        "mountPath": {
            "type": "string",
            "format": "unixpath",
            "prettyName": "Mount Path",
            "description": "Full path to where the VDB's data will be mounted on the target"
        }
    }
}
```

This data is entered by the user, once again we are being careful to disallow `additionalProperties`, to provide `prettyName` and `description`, and to specify that we want a valid Unix path.

## Implementing Provisioning

There are numerous ways for a plugin to customize the provisioning process. For full details see (link to reference).

For our simple plugin, we just need to do two things:

1. Tell Delphix where to mount the virtual dataset
2. Create a `sourceConfig` to represent each newly-provisioned virtual dataset.

### Controlling Mounting

In order to tell Delphix where we want our dataset mounted, we provide something called a [Mount Spec](/References/Glossary/#mountspec). To do this, we provide a customized plugin operation.

```python
@delphix.mount_spec
def get_mount_spec(virtual_source, snapshot):
    spec = MountSpec()
    spec.primary_mount = virtual_source.mountPath
    return spec
```

As we have seen in previous examples, we have a [decorator](/References/Glossary/#decorator) to tell Delphix that this is the function to call to get a mount spec.

In our case, the user has provided their desired mount location to us in the `virtual_source` object. All we need to do is to create a `MountSpec` object, and set the `primary_mount` accordingly.

This is perhaps the simplest possible mount spec operation. To see what other options are available to plugins here, refer to (link to reference).

### Creating the Source Config

Just like we saw earlier with [linked datasets](/References/Glossary/#linked-dataset), each virtual dataset will need its own source config so that the Delphix Engine can interact with it. Our plugin is in charge of creating that source config.

As a reminder, here is what our schema looks like for source configs:

```json
{
  "type": "object",
  "properties": {
    "name": {
      "type": "string",
      "prettyName": "Dataset Name",
      "description": "User-visible name for this dataset"
    }
    "path": {
      "type": "string",
      "format": "unixpath",
      "prettyName": "Path",
      "description": "Full path to data location on the remote environment"
    }
  },
  "required": ["name", "path"],
  "additionalFields": false,
  "nameField": "name",
  "identityFields": ["path"]
}
```

For each newly-cloned virtual dataset, we create a new source config object with a name and a path. This is done by the `configure` plugin operation.

In general, the job of the configure operation is to get the newly-cloned dataset ready for use on the target environment, and to return a new source config representing the new dataset. For our simple plugin, the dataset does not require any setup work, and so we only have to worry about the source config.

```python
@delphix.configure
def configure_new_vdb(virtual_source):
    sourceConfig = SourceConfig();

    # For our VDBs, the "path" is just the same thing as the location of the NFS mount
    sourceConfig.path = virtual_source.mountPath

    # A user-readable name for this dataset
    sourceConfig.name = "Directory tree at %s".format(virtual_source.mountPath)

    return sourceConfig
```

For more details about `configure`, please see (link to reference).

## How To Provision in the Delphix Engine

Finally, let us try it out to make sure provisioning works!

1. Login to the **Delphix Management** application.
2. Click **Manage > Dataset**.,
3. Select the dSource you created in the last page. You should see at least one snapshot, and maybe more than one if you have manually taken a snapshot, or if you have a snapshot policy in place. Select one of these snapshots and click the **Provision a VDB** icon.
4. This will open the Provision VDB wizard, complete the steps and select **Submit**.   
  During VDB provisioning one of the things you will have to do is to provide the data required by your virtual source schema. In our case, that means you will be asked to provide a value for `mountPath`.

  You will also be asked to choose a target environment on which the new VDB will live.

  After the wizard finishes, you will see a job appear on the right-hand side of the screen. When that job completes, your new VDB should be ready.

5. To ensure everything has worked correctly, log into to your target environment. From there, you can examine the directory you specified as the `mountPath`. What you should see is a copy of the directory that you linked to with your dSource.
